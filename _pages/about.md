---
permalink: /
author_profile: true
redirect_from:
  - /about/
  - /about.html
---


**News**

I am conducting a [usability study][31331d16] to identify physiciansâ€™ needs and requirements of explainable AI. If you are a physician and are interested in participating, please feel free to contact me.

  [31331d16]: https://weina.me/doctor-ai.html "doctor XAI user study"


## About Weina

Hi, I'm Weina. I'm a PhD student working on **interpretable AI (artificial intelligence)**, and how to use it to augment doctors' **clinical decision making**. It is interdisciplinary research among AI, computer vision, information visualization (InfoVis), human-computer interaction (HCI), and medicine. An explanation is a two-way communication/interaction between AI system and its users, that's where HCI and InfoVis come in. I'm also interested in using explanations for better learning, for both AI (enable AI to learn better by forcing explicit representation) and doctors (learn from those explicit representations to accumulate experience from big clinical data).

Previous I received my **Doctor of Medicine (MD)** degree and had worked in both the hospital and pharmaceutical industry. Now besides my research in training and making sense of artificial intelligence, in my life I am engaged in training and understanding natural intelligence, and writing science fictions.


## Publications
**Jin, W.**, Fatehi, M., Abhishek, K., Mallya, M., Toyota, B., & Hamarneh, G. (2019). **Applying Artificial Intelligence to Glioma Imaging: Advances and Challenges**. arXiv:1911.12886. [Paper](https://arxiv.org/pdf/1911.12886.pdf)    
- It summarizes the recent technical advances to overcome the practical challenges of applying AI to glioma imaging.
- These challenges involve the full life-cycle of developing an AI model, from obtaining the training data, to training the AI models, to evaluating and deploying the AI model to clinical settings.
- These efforts aim to make the AI-based tools to be fully implemented in neuro-oncology to significantly improve the care of patients with gliomas.


**Jin, W.**, Carpendale, S., Hamarneh, G., & Gromala, D. (2019). **Bridging AI Developers and End Users: an End-User-Centred Explainable AI Taxonomy and Visual Vocabularies**. IEEE VIS 2019 Conference Poster Abstract.
[Paper](http://weinajin.github.io/files/Bridging AI Developers and End Users--an End-User-Centred Explainable AI Taxonomy and Visual Vocabularies.pdf) [Poster](http://weinajin.github.io/files/201910_IEEE_VIS_poster.pdf)
- It summarize three user friendly forms to explain AI's decision to end users: explaining using *features*, *examples*, and *rules*.
