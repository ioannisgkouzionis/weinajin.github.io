---
title:  "[Reading] Deep learning, computer vision"
date:   2018-07-10 10:00:00
comments: true
#excerpt: ". "
tags:
  - annotated bibliography
---


1. B. Zoph and Q. V. Le, “Neural Architecture Search with Reinforcement Learning,” arXiv:1611.01578 [cs], Nov. 2016.

    **Reinforcement learning; hyperparameter optimization**

    Designing neural net architecture requires a lot of expert knowledge and ample time for trial-and-error. To improve this process of neural net design and hyperparameter searching, the researchers from Google applied reinforcement learning to this trial-and-error problem. They used a **RNN** as the **agent** that samples with probability *p* as **policy** to generate a string that specifies the network structure and connectivity. Thus, the generated CNN was trained on the real data and result in an **accuracy** as the **reward signal**. They then compute the **policy gradient** to update the **policy**. In this way, the controller leans to improve its search over time.

    In addition, the team applied the similar approach in the search of architecture with skip connections and other layer types such as pooling or batchnorm. It also used the reinforcement learning framework to generate recurrent cell architectures. The experiments showed that the model can compose novel network architecture that rivals the best human-invented architecture in terms of test set accuracy.


1. B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, “Learning Transferable Architectures for Scalable Image Recognition,” arXiv:1707.07012 [cs, stat], Jul. 2017.

    **Reinforcement learning, hyperparameter optimization**

    This work is from the same research group in Google as the above paper. It's a continuation to the above work of Neural Architecture Search (NAS). The NAS is computationally expensive since it will train multiple child networks on a large dataset. Therefore, the authors propose to search for architecture on a **proxy dataset**, and then transfer the learned architecture to a larger dataset. The main contribution of this work is the design of a novel search space, such that the best architecture found on the small dataset would scale to a larger dataset. It decouples the complexity of an architecture from the depth of a network, defines two building blocks (normal and reduction cells) which form the network by stacking alternately, and transferrers the same building block structure found on the small dataset to the large one by stacking more of the same building blocks. The structures of the building blocks are expressed with a sequence string and the best structure was searched with NAS framework on the small dataset. The resulting architectures approach or exceed state-of-the-art performance in both small and big dataset with less computation demand than human-designed architecture.



1. M. Zitnik and J. Leskovec, “Predicting multicellular function through multi-layer tissue networks,” Bioinformatics, vol. 33, no. 14, pp. i190–i198, Jul. 2017.

    **Feature learning for networks**

    The aim of the paper is to model functions of proteins in specific human tissues in the protein-protein interaction network. Previous works ignore and could not differentiate the protein functions in different tissues. This paper present *OhmNet*, which learns features of protein functions in a protein-protein interaction network with an unsupervised learning fashion of node2vec embedding. It encourages sharing of similar features among proteins with similar network neighborhoods. To reserve the hierarchical relationship of proteins in different tissues, the model uses mathematical regularization to express the fact that the proteins "stay together functions similar". Specifically, it incorporates a recursive structure into the regularization that enforces the proteins to have similar features of the same proteins in the parent layer. The results showed *OhmNet* provided more accurate predictions of cellular function than alternative approaches, and also generated more accurate hypotheses about tissue-specific protein actions.
