---
title:  "Paper Reading Notes on AI, HCI, decision-making, and explaination"
date:   2019-05-02 10:00:00
comments: true
excerpt: "My recent paper reading notes, loosely organized chronologically (mainly pasted from Mendeley)"
tags:
  - paper reading
---

- Darwiche, A. Human-Level Intelligence or Animal-Like Abilities? (2017).

This is a high-level commentary work from the conversation of the authors with many other people in and outside AI communities, on the current trends in AI. I get to know this work from Pearl's "the book of why". It sees the current deep learning trend as the curve fitting for the cognition functions (vision, language, speech recognition). It negates the recent progress in DL and contribute them to merely the improvement of computational power and data (which is true. It points out that NN is invented long ago).

It also emphasize on the explainability challenge in AI. A model-based approach can allow AI users to ask more questions (what if, conterfactual) that are beyond the ability of function-based apporach (rely on data-collection, input-output mapping). In this part, he quote Judea Pearl in the book of why ch1:


“There is only one way a thinking
entity (computer or human) can work
out what would happen in multiple
scenarios, including some that it has
never experienced before. It must pos-sess, consult, and manipulate a mental
causal model of that reality.”

It points out that "the vocabulary of (existing) explanations is restricted to the function inputs" (feature attribution). These limited vocabulary face challenges when encountering novel situations. According to Pearl, "model-based explanations are also important be-cause they give us a sense of “under-standing” or “being in control” of a phenomenon".

In the end, it points out the future challenge of AI should be combining the model and function based (mapping to slow and fast human thinking, which is interesting).
